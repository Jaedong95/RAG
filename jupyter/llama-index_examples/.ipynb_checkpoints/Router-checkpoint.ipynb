{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dc32bca-4e8f-47bd-805a-388f97c32c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
    "from llama_index.vector_stores import ChromaVectorStore\n",
    "from llama_index.readers.chroma import ChromaReader\n",
    "from llama_index import StorageContext, load_index_from_storage, load_indices_from_storage\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from llama_index.embeddings import HuggingFaceEmbedding\n",
    "from llama_index.llms import HuggingFaceLLM\n",
    "from llama_index.node_parser import SentenceSplitter \n",
    "from llama_index.schema import MetadataMode\n",
    "from IPython.display import Markdown, display\n",
    "from llama_index import QueryBundle \n",
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import TextStreamer, GenerationConfig\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer, LlamaTokenizerFast, BitsAndBytesConfig\n",
    "from llama_index.response_synthesizers import (\n",
    "    ResponseMode,\n",
    "    get_response_synthesizer,\n",
    ")\n",
    "import chromadb\n",
    "import transformers\n",
    "import pandas as pd\n",
    "import json \n",
    "import openai\n",
    "import os\n",
    "import getpass\n",
    "import torch"
   ]
  },
  {
   "cell_type": "raw",
   "id": "00fac997-9d1a-4b6a-8548-a50229414f5b",
   "metadata": {},
   "source": [
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    StorageContext,\n",
    "    SimpleKeywordTableIndex,\n",
    ")\n",
    "from llama_index.core import SummaryIndex\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.llms.openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c585baa9-62df-4b5b-9002-de8d13389e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_path = os.getcwd()\n",
    "data_path = os.path.join(default_path, '/rag/data')\n",
    "model_path = os.path.join(default_path, '/rag/models')\n",
    "config_path = os.path.join(default_path, '/rag/config')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ddba935f-8391-4fb6-9731-5fbc83a7f436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "OpenAI API Key: ········\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29e615ce-adc4-40f3-b1f8-ebf862421032",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = os.path.join(model_path, \"mistral_origin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56b720b7-7f2b-4934-bcc1-fd39ce870af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9f593fdbc594086bc30b3f34b057480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(os.path.join(model_dir, 'tokenizer'))   # LlamaTokenizer (x)  -> LlamaTokenizerFast (o)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_dir, torch_dtype=torch.float16, low_cpu_mem_usage=True) # , device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5fa515d-8a09-48e6-b90b-90b717a2b69c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MistralForCausalLM(\n",
       "  (model): MistralModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(g_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54444992-67e2-4fa3-9cc6-784ac8186375",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config = GenerationConfig(\n",
    "    temperature=0.8,\n",
    "    do_sample=True,\n",
    "    top_p=0.95,\n",
    "    max_new_tokens=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eae796ca-b3c7-4918-bb9d-c76094d7a80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['qualification', 'desc', 'features'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "235f8829-7a3e-4ef5-abf1-226924cb1775",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db = chromadb.HttpClient(host='192.168.0.146')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "080c52f9-ae15-4852-b10f-45f5ddf7a277",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_collection = vector_db.get_or_create_collection(\"desc\")\n",
    "feature_collection = vector_db.get_or_create_collection(\"feature\")\n",
    "qualification_collection = vector_db.get_or_create_collection(\"qualification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47f235eb-98ef-4226-acc0-cce25e29ccdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config = GenerationConfig(\n",
    "    temperature=0.8,\n",
    "    do_sample=True,\n",
    "    top_p=0.95,\n",
    "    max_new_tokens=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1be8c892-baa9-4d80-a69c-4e4fdcb5da6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'kakaobank/kf-deberta-base'\n",
    "embed_model = HuggingFaceEmbedding(model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7185680c-7c09-413b-aa29-99f38326b664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM is explicitly disabled. Using MockLLM.\n"
     ]
    }
   ],
   "source": [
    "service_context = ServiceContext.from_defaults(embed_model=embed_model, llm=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3792b4b-db7a-4a08-8ca2-63e74025238e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = SentenceSplitter(chunk_size=512, chunk_overlap=30)   # SentenceSplitter(chunk_size=1024, chunk_overlap=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "015bc0cd-70f9-4f7d-ab07-0dd1ab093ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM is explicitly disabled. Using MockLLM.\n"
     ]
    }
   ],
   "source": [
    "embedding_service = ServiceContext.from_defaults(node_parser=parser, embed_model=embed_model, llm=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e915e46-9596-4cca-ac84-aec0040cd77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_store = ChromaVectorStore(chroma_collection=desc_collection)\n",
    "feature_store = ChromaVectorStore(chroma_collection=feature_collection)\n",
    "qualification_store = ChromaVectorStore(chroma_collection=qualification_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa02984a-d302-4aba-b5ae-a2477329291c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# service_context 전달 안해주면 query 시 dimension 오류 발생 \n",
    "features_idx = VectorStoreIndex.from_vector_store(feature_store, service_context=embedding_service)\n",
    "desc_idx = VectorStoreIndex.from_vector_store(desc_store, service_context=embedding_service)\n",
    "qualification_idx = VectorStoreIndex.from_vector_store(qualification_store, service_context=embedding_service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1280d5fa-4975-44af-91b4-6b28e330fc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_retriever = features_idx.as_retriever()\n",
    "desc_retriever = desc_idx.as_retriever()\n",
    "qualification_retriever = qualification_idx.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "028a1623-f97f-4218-a75c-f4782d0d1b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.tools import RetrieverTool\n",
    "\n",
    "feature_tool = RetrieverTool.from_defaults(\n",
    "    retriever=features_retriever, \n",
    "    llm=None, \n",
    "    description=(\n",
    "        \"금융 상품 특징에 대해 물어볼 때 대답해줘\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11c557f3-50c4-4a00-883c-041293759fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_tool = RetrieverTool.from_defaults(\n",
    "    retriever=desc_retriever,\n",
    "    description=(\n",
    "        \"금융 상품 관련해서 설명을 요구할 때 대답해줘\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89a3b214-2652-4b34-928e-d2aabecefd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "qualification_tool = RetrieverTool.from_defaults(\n",
    "    retriever=qualification_retriever,\n",
    "    description=(\n",
    "        \"금융 상품 관련해서 자격 요건을 물어볼 때 대답해줘\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa4fb093-4fdc-42d1-b96f-bea988c01f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.selectors import LLMSingleSelector, LLMMultiSelector, EmbeddingSingleSelector\n",
    "'''from llama_index.selectors import (\n",
    "    PydanticMultiSelector,\n",
    "    PydanticSingleSelector,\n",
    ")'''\n",
    "from llama_index.retrievers import RouterRetriever\n",
    "from llama_index.response.notebook_utils import display_source_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a108ca5b-48c1-4135-ac63-59646783d2f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "EmbeddingSingleSelector.from_defaults() got an unexpected keyword argument 'service_context'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m retriever \u001b[38;5;241m=\u001b[39m RouterRetriever(\n\u001b[0;32m----> 2\u001b[0m     selector\u001b[38;5;241m=\u001b[39m\u001b[43mEmbeddingSingleSelector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_defaults\u001b[49m\u001b[43m(\u001b[49m\u001b[43mservice_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_service\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m      3\u001b[0m     retriever_tools\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m      4\u001b[0m         feature_tool,\n\u001b[1;32m      5\u001b[0m         desc_tool,\n\u001b[1;32m      6\u001b[0m         qualification_tool,\n\u001b[1;32m      7\u001b[0m     ],\n\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: EmbeddingSingleSelector.from_defaults() got an unexpected keyword argument 'service_context'"
     ]
    }
   ],
   "source": [
    "retriever = RouterRetriever(\n",
    "    selector=EmbeddingSingleSelector.from_defaults(embed_model=),\n",
    "    retriever_tools=[\n",
    "        feature_tool,\n",
    "        desc_tool,\n",
    "        qualification_tool,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac27125-ea04-4df2-a592-8d3b26e8221a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940bf9f8-01e8-4999-b9e2-da315253654c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_start_point(documents):\n",
    "    s_point = 1\n",
    "    for doc in documents:\n",
    "        if len(re.findall(r'제 *1 *장', doc.text)) != 0 and (len(re.findall(r'목 *차', doc.text)) == 0 and len(re.findall(r'차 *례', doc.text)) == 0): \n",
    "            '''\n",
    "            print(re.findall(r'제 *1 *장', doc.text))\n",
    "            print(re.findall(r'목 *차', doc.text))\n",
    "            print(re.findall(r'차 *례', doc.text))'''\n",
    "            s_point = doc.metadata['page_label']\n",
    "            break \n",
    "    return int(s_point) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab4c2da-3dbb-4ba3-885b-825642d08889",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_doc(idx, prev_spot, current_spot, document):\n",
    "    file_name = document.metadata['file_name'].split('.')[0]\n",
    "    splitted = document.text.split(current_spot)\n",
    "    prev_doc = Document(text=splitted[0],\n",
    "                       doc_id=f\"{file_name}_doc_{idx}\",\n",
    "                       metadata={\"spot\": prev_spot, \"file_name\": document.metadata['file_name']},\n",
    "                       excluded_llm_metadata_keys = ['spot', 'file_name']\n",
    "                )\n",
    "    current_doc = Document(text=splitted[1],\n",
    "                       doc_id=f\"{file_name}_doc_{idx + 1}\",\n",
    "                       metadata={\"spot\": current_spot, \"file_name\": document.metadata['file_name']},\n",
    "                       excluded_llm_metadata_keys = ['spot', 'file_name']\n",
    "                )\n",
    "    return idx + 2, prev_doc, current_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aea78d8-1e8a-4305-b19b-0abfb9017482",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_content(idx, document):  \n",
    "    '''\n",
    "    input: document (페이지 단위로 분할된 document object) \n",
    "    output: document_list (장 단위로 분할된 document objects) \n",
    "    '''\n",
    "    doc_list = []; meta_info = dict();\n",
    "    prev_spot = document.metadata['spot']\n",
    "    split_spot = re.findall(r'제 *[0-9] *장', document.text)\n",
    "    if len(split_spot) == 0:\n",
    "        return document\n",
    "        \n",
    "    splitted_docs = [] \n",
    "    for spot in split_spot:\n",
    "        new_idx, prev_doc, current_doc = split_doc(idx, prev_spot, spot, document)\n",
    "        prev_spot = spot\n",
    "        splitted_docs.append(prev_doc)\n",
    "        document = current_doc\n",
    "    return splitted_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aad794a-0293-4fa3-a4d9-b87b167d4e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(documents), s_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12aaf305-96ba-45b2-ba5d-8ba5267427a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents[s_point].metadata['spot'] = '제1장' \n",
    "for idx, doc in enumerate(documents):\n",
    "    if idx >= s_point: \n",
    "        get_doc_content(idx, doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36512556-e28e-4abe-ab27-505ea4fd4acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents[2].text.split('제2장')[1].split('제 3장')   #, documents[2].text.split('제2장')[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
